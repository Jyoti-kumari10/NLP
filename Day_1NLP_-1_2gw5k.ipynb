{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947fc6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5c8fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPreprocessing steps :\\n1. Lowercase\\n2. Remove HTML tags & URLs\\n3. Remove Punctuations\\n4. Remove Stop words\\n5. Tokenization\\n6. Stemming\\n7. Lemmatization\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Preprocessing steps :\n",
    "1. Lowercase\n",
    "2. Remove HTML tags & URLs\n",
    "3. Remove Punctuations\n",
    "4. Remove Stop words\n",
    "5. Tokenization\n",
    "6. Stemming\n",
    "7. Lemmatization\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0034f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae0a5915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB-Dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c735de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595ae23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: lowercase\n",
    "data['review'] = data['review'].str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccccab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.1: Remove HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2353435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f147858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95f5fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8f0f119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88c2fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.2: Remove URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0f2b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "432e0be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Check out my notebook at www.//kaggle.com/notebook123'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07acf0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my notebook at '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed36facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56ddd905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f0fd5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13eb0f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ebe43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char , '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15eadbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stringWithPunctuation'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'string:With.Punctuation?'\n",
    "remove_punc(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db44e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f736c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basically theres a family where a little boy jake thinks theres a zombie in his closet  his parents are fighting all the timethis movie is slower than a soap opera and suddenly jake decides to become rambo and kill the zombieok first of all when youre going to make a film you must decide if its a thriller or a drama as a drama the movie is watchable parents are divorcing  arguing like in real life and then we have jake with his closet which totally ruins all the film i expected to see a boogeyman similar movie and instead i watched a drama with some meaningless thriller spots3 out of 10 just for the well playing parents  descent dialogs as for the shots with jake just ignore them'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7010e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Remove Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d447c201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04e1035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aber', 'alle', 'allem', 'allen', 'aller', 'alles', 'als', 'also', 'am', 'an', 'ander', 'andere', 'anderem', 'anderen', 'anderer', 'anderes', 'anderm', 'andern', 'anderr', 'anders', 'auch', 'auf', 'aus', 'bei', 'bin', 'bis', 'bist', 'da', 'damit', 'dann', 'der', 'den', 'des', 'dem', 'die', 'das', 'dass', 'daß', 'derselbe', 'derselben', 'denselben', 'desselben', 'demselben', 'dieselbe', 'dieselben', 'dasselbe', 'dazu', 'dein', 'deine', 'deinem', 'deinen', 'deiner', 'deines', 'denn', 'derer', 'dessen', 'dich', 'dir', 'du', 'dies', 'diese', 'diesem', 'diesen', 'dieser', 'dieses', 'doch', 'dort', 'durch', 'ein', 'eine', 'einem', 'einen', 'einer', 'eines', 'einig', 'einige', 'einigem', 'einigen', 'einiger', 'einiges', 'einmal', 'er', 'ihn', 'ihm', 'es', 'etwas', 'euer', 'eure', 'eurem', 'euren', 'eurer', 'eures', 'für', 'gegen', 'gewesen', 'hab', 'habe', 'haben', 'hat', 'hatte', 'hatten', 'hier', 'hin', 'hinter', 'ich', 'mich', 'mir', 'ihr', 'ihre', 'ihrem', 'ihren', 'ihrer', 'ihres', 'euch', 'im', 'in', 'indem', 'ins', 'ist', 'jede', 'jedem', 'jeden', 'jeder', 'jedes', 'jene', 'jenem', 'jenen', 'jener', 'jenes', 'jetzt', 'kann', 'kein', 'keine', 'keinem', 'keinen', 'keiner', 'keines', 'können', 'könnte', 'machen', 'man', 'manche', 'manchem', 'manchen', 'mancher', 'manches', 'mein', 'meine', 'meinem', 'meinen', 'meiner', 'meines', 'mit', 'muss', 'musste', 'nach', 'nicht', 'nichts', 'noch', 'nun', 'nur', 'ob', 'oder', 'ohne', 'sehr', 'sein', 'seine', 'seinem', 'seinen', 'seiner', 'seines', 'selbst', 'sich', 'sie', 'ihnen', 'sind', 'so', 'solche', 'solchem', 'solchen', 'solcher', 'solches', 'soll', 'sollte', 'sondern', 'sonst', 'über', 'um', 'und', 'uns', 'unsere', 'unserem', 'unseren', 'unser', 'unseres', 'unter', 'viel', 'vom', 'von', 'vor', 'während', 'war', 'waren', 'warst', 'was', 'weg', 'weil', 'weiter', 'welche', 'welchem', 'welchen', 'welcher', 'welches', 'wenn', 'werde', 'werden', 'wie', 'wieder', 'will', 'wir', 'wird', 'wirst', 'wo', 'wollen', 'wollte', 'würde', 'würden', 'zu', 'zum', 'zur', 'zwar', 'zwischen']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('german'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d5071f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aebdb465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably   time fav movie,  story  selflessness'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1 = remove_stopwords('probably my all time fav movie, a story of selflessness')\n",
    "str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7888ae90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcc4fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['review'] = data['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be251c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3818eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4faf9433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Delhi', '!']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'I am going to Delhi!'\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dc85784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Delhi!']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ecc9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Lorem Ipsum is simply dummy text of the printing and typesetting industry?\n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23b96a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry?',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt1  = sent_tokenize(text)\n",
    "txt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afa79185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(txt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "046396e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem Ipsum is simply dummy text of the printing and typesetting industry?\n",
      "Lorem Ipsum  simply dummy text   printing  typesetting industry?\n",
      "['Lorem', 'Ipsum', 'simply', 'dummy', 'text', 'printing', 'typesetting', 'industry', '?']\n",
      "\n",
      "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
      "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\n",
      "Lorem Ipsum    industry's standard dummy text ever since  1500s,   unknown printer took  galley  type  scrambled   make  type specimen book.\n",
      "['Lorem', 'Ipsum', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', '1500s', ',', 'unknown', 'printer', 'took', 'galley', 'type', 'scrambled', 'make', 'type', 'specimen', 'book', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in txt1:\n",
    "    print(x)\n",
    "    x1 = remove_stopwords(x)\n",
    "    print(x1)\n",
    "    wx1 = word_tokenize(x1)\n",
    "    print(wx1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90c31d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter: walk : walk\n",
      "Lancaster: walk : walk\n",
      "Snowball: walk : walk\n",
      "\n",
      "Porter: walks : walk\n",
      "Lancaster: walks : walk\n",
      "Snowball: walks : walk\n",
      "\n",
      "Porter: walking : walk\n",
      "Lancaster: walking : walk\n",
      "Snowball: walking : walk\n",
      "\n",
      "Porter: walked : walk\n",
      "Lancaster: walked : walk\n",
      "Snowball: walked : walk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "pst = PorterStemmer()\n",
    "lst = LancasterStemmer()\n",
    "snb = SnowballStemmer('english')\n",
    "\n",
    "words_to_stem = ['walk', 'walks', 'walking', 'walked']\n",
    "for words in words_to_stem:\n",
    "    print(\"Porter: \" + words + ' : ' + pst.stem(words))\n",
    "    print(\"Lancaster: \" + words + ' : ' + lst.stem(words))\n",
    "    print(\"Snowball: \" + words + ' : ' + snb.stem(words))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "488717d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter: give : give\n",
      "Lancaster: give : giv\n",
      "Snowball: give : give\n",
      "\n",
      "Porter: giving : give\n",
      "Lancaster: giving : giv\n",
      "Snowball: giving : give\n",
      "\n",
      "Porter: given : given\n",
      "Lancaster: given : giv\n",
      "Snowball: given : given\n",
      "\n",
      "Porter: gave : gave\n",
      "Lancaster: gave : gav\n",
      "Snowball: gave : gave\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = ['give', 'giving', 'given', 'gave']\n",
    "for words in words_to_stem:\n",
    "    print(\"Porter: \" + words + ' : ' + pst.stem(words))\n",
    "    print(\"Lancaster: \" + words + ' : ' + lst.stem(words))\n",
    "    print(\"Snowball: \" + words + ' : ' + snb.stem(words))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c68df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "535cf8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lem.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9d7ce4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run : run\n",
      "running : run\n",
      "ran : run\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = ['run', 'running', 'ran']\n",
    "for words in words_to_stem:\n",
    "    print(words + ' : ' + word_lem.lemmatize(words, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef886e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
